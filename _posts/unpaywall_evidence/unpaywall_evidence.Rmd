---
title: "Open Access Evidence in Unpaywall"
description: |
  Unpaywall has become a primary source to find open access full-texts. We investigated more than 42 million scholarly works contained in Unpaywall that were published between 2008 - 2018 with Google BigQuery and R. Our data analysis revealed various open access location types and large overlaps between them, raising important questions about how to reponsibly re-use Unpaywall data in bibliometric research and open access monitoring.
author:
  - name: Najko Jahn 
    url: https://twitter.com/najkoja
    affiliation: State and University Library Göttingen
    affiliation_url: https://www.sub.uni-goettingen.de/
  - name: Anne Hobert
    affiliation: State and University Library Göttingen
    affiliation_url: https://www.sub.uni-goettingen.de/
date: "`r Sys.Date()`"
creative_commons: CC BY
output: distill::distill_article
draft: true
---

```{r, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  echo = TRUE
)
options(scipen = 999, digits = 2)
knitr::knit_hooks$set(
  inline = function(x) {
    if (is.numeric(x)) {
      return(prettyNum(x, big.mark = ","))
    } else{
      return(x)
    }
  }
)
# libraries
library(tidyverse)
library(DBI)
library(bigrquery)
library(scales)
library(plotly)
# ggplot theme
 sub_theme <- theme_minimal(base_family="Roboto") +
  theme(plot.margin=margin(30,30,30,30)) +
  theme(panel.grid.minor=element_blank()) +
  theme(axis.ticks=element_blank()) +
  theme(panel.grid.major.x=element_blank()) +
  theme(panel.border=element_blank())
```

[Unpaywall](https://unpaywall.org/), developed and maintained by the [team of Impactstory](http://impactstory.org/team), is a non-profit service that finds open access copies of scholarly literature. Providing DOIs, [Unpaywall's REST API](https://unpaywall.org/products/api) not only returns open access full-text links, but also helpful metadata about the open access status of a publication indexed in [Crossref](https://www.crossref.org/). While the API is useful for a limited amount of scholarly works, Unpaywall also provides [database snapshots](https://unpaywall.org/products/snapshot) for large-scale analysis. Many bibliometric databases and open access monitoring activities re-use Unpaywall data.

In this blog post, we show how we made use of the Unpaywall data dump in conjunction with [Google BigQuery](https://cloud.google.com/bigquery/), a cloud-based service that allows fast analysis of large datasets, and how we interfaced it for our analysis with R. We wanted to know the extent of open access status information in Unpaywall, particularly, how this information can be utilized for bibliometric research. In our case, we intend to match evidence from Unpaywall with the Web of Science in-house database from the [German Competence Center for Bibliometrics](http://www.bibliometrie.info/) to determine factors influencing open access publication activities among German Universities as part of our [BMBF-funded research project OAUNI](https://www.wihoforschung.de/de/oauni-2182.php).

## Setting up Google Big Query

## Unpaywall Overview

To investigate the overall number and proportion of journal articles provided using Unpaywall, we firstly connect to Google BigQuery with using the [DBI interface](https://www.r-dbi.org/) and [bigrquery](https://github.com/r-dbi/bigrquery).


```{r fetch_bq}
#' connect to google bg where we imported the jsonl Unpaywall dump
library(DBI)
library(bigrquery)
con <- dbConnect(
  bigrquery::bigquery(),
  project = "api-project-764811344545",
  dataset = "oadoi_full"
)
```

Our BigQuery project has two table, one containing all records between 2008 - 2012, and another with publications since 2019. When connecting, Google will ask you to login via your web browser or to supply an private access token.

```{r}
upw_08_12 <- tbl(con, "feb_19_mongo_export_2008_2012_full_all_genres")
upw_13_19 <- tbl(con, "feb_19_mongo_export_2013_Feb2019_full_all_genres")
```

The [bigrquery](https://github.com/r-dbi/bigrquery) package allows querying BigQuery tables using SQL or the dplyr syntax. The latter is very convienent when you just started to learn SQL, but feel more experienced in using the dplyr grammar.

Let's retrieve the number and proportion of journal articles with open access fulltext between 2008 and 2018. `collect()` loads the data into a local tibble.

```{r cache=TRUE}
library(tidyverse)
oa_08_12 <- upw_08_12 %>%
  filter(genre == "journal-article") %>%
  group_by(year, is_oa) %>%
  summarise(n = n()) %>% 
  collect()
oa_13_18 <- upw_13_19 %>%
  filter(genre == "journal-article", year < 2019) %>%
  group_by(year, is_oa) %>%
  summarise(n = n()) %>% 
  collect()
my_df <- bind_rows(oa_08_12, oa_13_18) %>%
  # calculate proportion per year
  ungroup() %>%
  mutate(year = as.Date(as.character(year), format = "%Y")) %>%
  group_by(year, is_oa) %>%
  summarise(n = sum(n)) %>%
  mutate(prop = n / sum(n))
my_df
```

Next let's visualise our so retrieved data and transform the ggplot2 object into a plotly graph the plt interactive with `plotly

```{r}
plot_a <- ggplot(my_df, aes(year, n)) +
         geom_area(aes(fill = is_oa, group = is_oa),  alpha = 0.8) + 
  labs(x = "Year", y = "Crossref records") +
  scale_fill_manual("Open Access Full-Text available?", 
                    values = c("#b3b3b3a0", "#56B4E9")) +
  scale_x_date(date_labels = "%y") + 
  scale_y_continuous(labels = scales::number_format(big.mark = " ")) +
  theme_minimal(base_family="Roboto") +
  theme(plot.margin=margin(30,30,30,30)) +
  theme(panel.grid.minor=element_blank()) +
  theme(axis.ticks=element_blank()) +
  theme(panel.grid.major.x=element_blank()) +
  theme(panel.border=element_blank()) 
plotly::ggplotly(plot_a)
```

## Unpaywall OA location types


## Unpaywall OA evidence types

## Discussion and Conclusion


